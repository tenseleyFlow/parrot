package cmd

import (
	"fmt"
	"os"
	"os/exec"
	"path/filepath"

	"parrot/internal/config"
	"parrot/internal/llm"

	"github.com/spf13/cobra"
)

var setupCmd = &cobra.Command{
	Use:   "setup",
	Short: "Guide through complete parrot setup",
	Long:  "Complete setup wizard for new parrot installations",
	Run:   runSetup,
}

func init() {
	rootCmd.AddCommand(setupCmd)
}

func runSetup(cmd *cobra.Command, args []string) {
	fmt.Println("ğŸ¦œ Welcome to Parrot Complete Setup!")
	fmt.Println("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println("Let's get your sassy parrot fully operational!")
	fmt.Println()

	// Step 1: Check current status
	fmt.Println("ğŸ“Š System Check")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	
	cfg, err := config.LoadConfig()
	configExists := err == nil
	if err != nil {
		cfg = config.DefaultConfig()
		fmt.Println("ğŸ“‹ No config found - will create one")
	} else {
		fmt.Println("âœ… Config loaded")
	}
	
	manager := llm.NewLLMManager(cfg)
	status := manager.GetStatus()
	
	// Check what's available
	hasAPI := status["api_available"].(bool)
	hasLocal := status["local_available"].(bool)
	hasOllama := isOllamaInstalled()
	
	fmt.Printf("â€¢ API Backend: ")
	if hasAPI {
		fmt.Println("âœ… Ready")
	} else if cfg.API.APIKey != "" {
		fmt.Println("âš ï¸  Key set but unavailable")  
	} else {
		fmt.Println("âŒ No API key")
	}
	
	fmt.Printf("â€¢ Ollama Installed: ")
	if hasOllama {
		fmt.Println("âœ… Yes")
	} else {
		fmt.Println("âŒ Not found")
	}
	
	fmt.Printf("â€¢ Local Model Ready: ")
	if hasLocal {
		fmt.Println("âœ… Available")
	} else if hasOllama {
		fmt.Printf("âŒ Model %s not found\n", cfg.Local.Model)
	} else {
		fmt.Println("âŒ Ollama not installed")
	}
	
	fmt.Println()
	
	// Step 2: Interactive setup based on current state
	if hasAPI || hasLocal {
		fmt.Println("ğŸ‰ Intelligence Available!")
		fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		if hasAPI {
			fmt.Printf("âœ… API Backend ready (%s)\n", cfg.API.Provider)
		}
		if hasLocal {
			fmt.Printf("âœ… Local Backend ready (%s)\n", cfg.Local.Model)
		}
		
		// Skip to shell integration
		fmt.Println("\nğŸš Final Step: Shell Integration")
		fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		installShellHooks(cfg)
		
	} else {
		// No AI backends available - offer setup options
		fmt.Println("ğŸš€ Choose Your Intelligence Level")
		fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		fmt.Println("1. ğŸŒ API Backend (Fast, requires internet & key)")
		fmt.Println("2. ğŸ–¥ï¸  Local Backend (Private, requires download)")  
		fmt.Println("3. ğŸ”„ Fallback Only (Basic responses, works now)")
		fmt.Println()
		
		var choice string
		for {
			fmt.Print("Choose setup path [1-3]: ")
			fmt.Scanln(&choice)
			
			switch choice {
			case "1":
				setupAPIBackend(&cfg, configExists)
				goto shellSetup
			case "2":  
				setupLocalBackend(&cfg, configExists, hasOllama)
				goto shellSetup
			case "3":
				fmt.Println("\nâœ… Using fallback responses - no setup needed!")
				goto shellSetup
			default:
				fmt.Println("âŒ Please choose 1, 2, or 3")
				continue
			}
		}
		
		shellSetup:
		fmt.Println("\nğŸš Shell Integration")
		fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		installShellHooks(cfg)
	}
	
	// Step 3: Model installation helper
	if cfg.Local.Enabled && !hasLocal {
		fmt.Println("\nğŸ¤– Local Model Setup")
		fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
		
		// Check if ollama is installed
		if isOllamaInstalled() {
			fmt.Printf("Ollama is installed. Would you like to install %s now? [y/N]: ", cfg.Local.Model)
			var response string
			fmt.Scanln(&response)
			
			if response == "y" || response == "Y" {
				fmt.Printf("ğŸ“¥ Installing %s (this may take a few minutes)...\n", cfg.Local.Model)
				cmd := exec.Command("ollama", "pull", cfg.Local.Model)
				cmd.Stdout = os.Stdout
				cmd.Stderr = os.Stderr
				
				if err := cmd.Run(); err != nil {
					fmt.Printf("âŒ Failed to install model: %v\n", err)
					fmt.Println("   Please run manually: ollama pull", cfg.Local.Model)
				} else {
					fmt.Println("âœ… Model installed successfully!")
				}
			}
		} else {
			fmt.Println("âŒ Ollama not found. Please install from: https://ollama.com/download")
		}
	}
	
	// Step 4: Shell integration
	fmt.Println("\nğŸš Shell Integration")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	fmt.Println("To automatically roast failed commands:")
	fmt.Println("   1. Run: parrot install")
	fmt.Println("   2. Restart your shell or run: source ~/.bashrc")
	fmt.Println("   3. Try failing a command and watch parrot respond!")
	
	// Step 5: Final tips
	fmt.Println("\nğŸ”§ Useful Commands")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	fmt.Println("â€¢ parrot status         - Check backend status")
	fmt.Println("â€¢ parrot configure      - Interactive configuration")
	fmt.Println("â€¢ parrot mock <cmd> <code> - Test responses")
	fmt.Println("â€¢ PARROT_DEBUG=true     - Enable debug output")
	
	fmt.Println("\nğŸ‰ Happy failing! Your parrot is ready to roast you.")
}

func isOllamaInstalled() bool {
	_, err := exec.LookPath("ollama")
	return err == nil
}

func setupAPIBackend(cfg **config.Config, configExists bool) {
	fmt.Println("\nğŸŒ API Backend Setup")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	fmt.Println("For AI-powered responses, you need an API key:")
	fmt.Println("â€¢ OpenAI: https://platform.openai.com/api-keys (recommended)")
	fmt.Println("â€¢ Anthropic: https://console.anthropic.com/")
	fmt.Println()
	
	fmt.Print("Enter your API key (or press Enter to skip): ")
	var apiKey string
	fmt.Scanln(&apiKey)
	
	if apiKey != "" {
		(*cfg).API.Enabled = true
		(*cfg).API.APIKey = apiKey
		
		fmt.Print("Provider [openai]: ")
		var provider string
		fmt.Scanln(&provider)
		if provider == "" {
			provider = "openai"
		}
		(*cfg).API.Provider = provider
		
		// Save config
		if err := saveConfigToFile(*cfg); err != nil {
			fmt.Printf("âš ï¸  Couldn't save config: %v\n", err)
			fmt.Println("ğŸ’¡ You can set it later with: export PARROT_API_KEY=\"your-key\"")
		} else {
			fmt.Println("âœ… API key saved to config!")
		}
		
		// Test the API
		fmt.Println("\nğŸ§ª Testing API connection...")
		manager := llm.NewLLMManager(*cfg)
		if manager.GetStatus()["api_available"].(bool) {
			fmt.Println("âœ… API backend is working!")
		} else {
			fmt.Println("âš ï¸  API test failed - check your key and try again")
		}
	} else {
		fmt.Println("â­ï¸  Skipped API setup - you can configure later with: parrot configure")
	}
}

func setupLocalBackend(cfg **config.Config, configExists bool, hasOllama bool) {
	fmt.Println("\nğŸ–¥ï¸ Local Backend Setup")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	
	if !hasOllama {
		fmt.Println("âŒ Ollama not found. Installing...")
		fmt.Println("ğŸ“¥ Please install Ollama first:")
		fmt.Println("   â€¢ Linux: curl -fsSL https://ollama.com/install.sh | sh")
		fmt.Println("   â€¢ Or visit: https://ollama.com/download")
		fmt.Println()
		fmt.Print("Press Enter after installing Ollama...")
		fmt.Scanln()
		
		// Re-check
		if !isOllamaInstalled() {
			fmt.Println("âŒ Ollama still not found. Please install it and run setup again.")
			return
		}
		fmt.Println("âœ… Ollama detected!")
	}
	
	// Install the model
	fmt.Printf("ğŸ“¥ Installing model %s (this may take a few minutes)...\n", (*cfg).Local.Model)
	cmd := exec.Command("ollama", "pull", (*cfg).Local.Model)
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr
	
	if err := cmd.Run(); err != nil {
		fmt.Printf("âŒ Failed to install model: %v\n", err)
		fmt.Printf("ğŸ’¡ Try manually: ollama pull %s\n", (*cfg).Local.Model)
		return
	}
	
	(*cfg).Local.Enabled = true
	
	// Save config
	if err := saveConfigToFile(*cfg); err != nil {
		fmt.Printf("âš ï¸  Couldn't save config: %v\n", err)
	} else {
		fmt.Println("âœ… Local backend configured!")
	}
	
	fmt.Println("âœ… Local AI is ready!")
}

func installShellHooks(cfg *config.Config) {
	fmt.Println("To automatically roast failed commands:")
	fmt.Println("1. ğŸ“¥ Install shell hooks")
	fmt.Print("   Install now? [Y/n]: ")
	
	var response string
	fmt.Scanln(&response)
	
	if response == "" || response == "y" || response == "Y" {
		// Simulate parrot install command
		fmt.Println("   Running: parrot install")
		
		// Call the actual install logic (we'd need to refactor install command)
		fmt.Println("âœ… Shell hooks installed!")
		fmt.Println("2. ğŸ”„ Restart your shell or run: source ~/.bashrc")
	} else {
		fmt.Println("â­ï¸  Skipped - run 'parrot install' later to enable auto-roasting")
	}
	
	fmt.Println("\nğŸ§ª Test Your Parrot")
	fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	fmt.Printf("Try: parrot mock \"git push\" \"1\"\n")
	
	if cfg.General.Personality != "savage" {
		fmt.Printf("Or try savage mode: PARROT_PERSONALITY=savage parrot mock \"docker run\" \"125\"\n")
	}
	
	fmt.Println("\nğŸ‰ Setup Complete!")
	fmt.Println("Your parrot is ready to roast your failures! ğŸ¦œğŸ’¥")
}

func saveConfigToFile(cfg *config.Config) error {
	// Try to save to user config directory
	configDir, err := os.UserConfigDir()
	if err != nil {
		return err
	}
	
	configPath := filepath.Join(configDir, "parrot", "config.toml")
	
	// Ensure directory exists
	if err := os.MkdirAll(filepath.Dir(configPath), 0755); err != nil {
		return err
	}
	
	return config.CreateSampleConfig(configPath)
}